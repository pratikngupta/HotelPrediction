{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-12T11:24:15.118181Z",
     "start_time": "2023-04-12T11:24:08.677719Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-12 20:52:51.125414: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-11-12 20:52:51.156979: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-12 20:52:51.157017: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-12 20:52:51.157039: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-12 20:52:51.163149: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-12 20:52:52.419326: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-12 20:52:52.423368: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-12 20:52:52.423521: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-12T11:24:18.646740Z",
     "start_time": "2023-04-12T11:24:18.572591Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing successful\n",
      "train dataset column\n",
      "       BookingID  LeadTime  ArrivalYear  ArrivalMonth  ArrivalDate  \\\n",
      "0              1        10         2018             3           31   \n",
      "1              2       116         2018             2           28   \n",
      "2              3        11         2018             7           25   \n",
      "3              4         3         2017             9           12   \n",
      "4              5        28         2018             3            7   \n",
      "...          ...       ...          ...           ...          ...   \n",
      "29015      29016         2         2018            11           21   \n",
      "29016      29017        18         2018             4           12   \n",
      "29017      29018         8         2017             9           29   \n",
      "29018      29019        20         2018             9           18   \n",
      "29019      29020       274         2018             7           31   \n",
      "\n",
      "       NumWeekendNights  NumWeekNights      MealPlan  Parking     RoomType  \\\n",
      "0                     0              1   Meal Plan 1        0  Room_Type 1   \n",
      "1                     2              1   Meal Plan 1        0  Room_Type 1   \n",
      "2                     1              2   Meal Plan 1        0  Room_Type 1   \n",
      "3                     0              1   Meal Plan 1        0  Room_Type 1   \n",
      "4                     1              3   Meal Plan 1        0  Room_Type 1   \n",
      "...                 ...            ...           ...      ...          ...   \n",
      "29015                 1              2   Meal Plan 1        0  Room_Type 1   \n",
      "29016                 0              2  Not Selected        0  Room_Type 1   \n",
      "29017                 0              3   Meal Plan 1        0  Room_Type 1   \n",
      "29018                 2              2   Meal Plan 1        0  Room_Type 1   \n",
      "29019                 2              1   Meal Plan 1        0  Room_Type 2   \n",
      "\n",
      "       NumAdults  NumChildren MarketSegment  RepeatedGuest  \\\n",
      "0              1            0     Corporate              0   \n",
      "1              1            0        Online              0   \n",
      "2              2            1        Online              0   \n",
      "3              2            0        Online              0   \n",
      "4              2            0       Offline              0   \n",
      "...          ...          ...           ...            ...   \n",
      "29015          1            0        Online              0   \n",
      "29016          2            0        Online              0   \n",
      "29017          1            0     Corporate              0   \n",
      "29018          1            0       Offline              0   \n",
      "29019          2            0        Online              0   \n",
      "\n",
      "       NumPrevCancellations  NumPreviousNonCancelled  AvgRoomPrice  \\\n",
      "0                         0                        0         95.00   \n",
      "1                         0                        0         61.00   \n",
      "2                         0                        0        129.75   \n",
      "3                         0                        0        152.00   \n",
      "4                         0                        0         87.00   \n",
      "...                     ...                      ...           ...   \n",
      "29015                     0                        0        100.67   \n",
      "29016                     0                        0        119.00   \n",
      "29017                     0                        0         65.00   \n",
      "29018                     0                        0         90.00   \n",
      "29019                     0                        0         96.50   \n",
      "\n",
      "       SpecialRequests BookingStatus  \n",
      "0                    0      Canceled  \n",
      "1                    0      Canceled  \n",
      "2                    1  Not_Canceled  \n",
      "3                    3  Not_Canceled  \n",
      "4                    0  Not_Canceled  \n",
      "...                ...           ...  \n",
      "29015                1  Not_Canceled  \n",
      "29016                1  Not_Canceled  \n",
      "29017                0  Not_Canceled  \n",
      "29018                0      Canceled  \n",
      "29019                1  Not_Canceled  \n",
      "\n",
      "[29020 rows x 19 columns]\n"
     ]
    }
   ],
   "source": [
    "print (\"importing successful\")\n",
    "train = pd.read_csv('train.csv')\n",
    "\n",
    "print (\"train dataset column\")\n",
    "print(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-12T11:24:23.527638Z",
     "start_time": "2023-04-12T11:24:23.499749Z"
    }
   },
   "outputs": [],
   "source": [
    "train.dropna(inplace=True)\n",
    "\n",
    "# Encode categorical features\n",
    "label_encoder = LabelEncoder()\n",
    "train['BookingStatus'] = label_encoder.fit_transform(train['BookingStatus'])\n",
    "train['MarketSegment'] = label_encoder.fit_transform(train['MarketSegment'])\n",
    "train['MealPlan'] = label_encoder.fit_transform(train['MealPlan'])\n",
    "train['RoomType'] = label_encoder.fit_transform(train['RoomType'])\n",
    "\n",
    "# Add new feature 'leadTime'\n",
    "train['leadTime'] = train['LeadTime'] / 365.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-12T11:24:29.842633Z",
     "start_time": "2023-04-12T11:24:29.797942Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"# Feature Engineering \"\"\"\n",
    "\n",
    "# Separate features and target variable\n",
    "# Separate features and target variable\n",
    "X = train[['ArrivalMonth', 'AvgRoomPrice', 'MarketSegment', 'MealPlan', 'NumAdults', 'NumChildren', 'NumPrevCancellations', 'NumPreviousNonCancelled', 'NumWeekNights', 'NumWeekendNights', 'RepeatedGuest', 'RoomType', 'SpecialRequests', 'leadTime']]\n",
    "y = train['BookingStatus']\n",
    "\n",
    "# Split data into train and test sets\n",
    "# Split the data into training, validation, and test sets\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_trainval, y_trainval, test_size=0.75, random_state=42)\n",
    "\n",
    "\n",
    "# Normalize features\n",
    "mean = X_train.mean(axis=0)\n",
    "std = X_train.std(axis=0)\n",
    "X_train = (X_train - mean) / std\n",
    "X_test = (X_test - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-12T11:24:31.047691Z",
     "start_time": "2023-04-12T11:24:30.764859Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 256)               3840      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 128)               512       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 64)                256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 32)                128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 48001 (187.50 KB)\n",
      "Trainable params: 47553 (185.75 KB)\n",
      "Non-trainable params: 448 (1.75 KB)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-12 20:53:07.801715: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-12 20:53:07.801984: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-12 20:53:07.802102: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-12 20:53:07.845025: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-12 20:53:07.845190: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-12 20:53:07.845309: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-12 20:53:07.845406: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2740 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650 with Max-Q Design, pci bus id: 0000:02:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "\"\"\"# Model Selection\"\"\"\n",
    "\n",
    "# Create model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(256, activation=\"relu\", input_shape=(X_train.shape[1],), kernel_regularizer = tf.keras.regularizers.l1(0.01)),\n",
    "    tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(32, activation=\"relu\"),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "model.summary()\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-12T11:26:10.590147Z",
     "start_time": "2023-04-12T11:25:55.961196Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-12 20:53:12.984987: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f98b4db78c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-11-12 20:53:12.985029: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1650 with Max-Q Design, Compute Capability 7.5\n",
      "2023-11-12 20:53:12.988719: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-11-12 20:53:12.999853: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8600\n",
      "2023-11-12 20:53:13.069365: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59/59 [==============================] - 3s 10ms/step - loss: 2.7525 - accuracy: 0.7669 - val_loss: 3.7967 - val_accuracy: 0.3456\n",
      "Epoch 2/40\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.7733 - accuracy: 0.8244 - val_loss: 3.1367 - val_accuracy: 0.3469\n",
      "Epoch 3/40\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.2338 - accuracy: 0.8341 - val_loss: 4.9234 - val_accuracy: 0.3455\n",
      "Epoch 4/40\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0234 - accuracy: 0.8258 - val_loss: 7.2810 - val_accuracy: 0.3453\n",
      "Epoch 5/40\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 0.8825 - accuracy: 0.8355 - val_loss: 6.3792 - val_accuracy: 0.3469\n",
      "Epoch 6/40\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 0.7480 - accuracy: 0.8434 - val_loss: 9.7983 - val_accuracy: 0.3479\n",
      "Epoch 7/40\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 0.6686 - accuracy: 0.8455 - val_loss: 6.5192 - val_accuracy: 0.3793\n",
      "Epoch 8/40\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 0.7055 - accuracy: 0.8293 - val_loss: 19.9763 - val_accuracy: 0.3448\n",
      "Epoch 9/40\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 0.6699 - accuracy: 0.8324 - val_loss: 3.8539 - val_accuracy: 0.4224\n",
      "Epoch 10/40\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 0.6284 - accuracy: 0.8317 - val_loss: 11.1255 - val_accuracy: 0.3477\n",
      "Epoch 11/40\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 0.5711 - accuracy: 0.8384 - val_loss: 7.8666 - val_accuracy: 0.6703\n",
      "Epoch 12/40\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 0.5662 - accuracy: 0.8405 - val_loss: 5.5632 - val_accuracy: 0.4524\n",
      "Epoch 13/40\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 0.5239 - accuracy: 0.8415 - val_loss: 7.7043 - val_accuracy: 0.4247\n",
      "Epoch 14/40\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 0.5482 - accuracy: 0.8415 - val_loss: 7.1352 - val_accuracy: 0.4453\n",
      "Epoch 15/40\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 0.4991 - accuracy: 0.8394 - val_loss: 2.9279 - val_accuracy: 0.5748\n",
      "Epoch 16/40\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 0.4791 - accuracy: 0.8475 - val_loss: 7.7152 - val_accuracy: 0.4324\n",
      "Epoch 17/40\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 0.4806 - accuracy: 0.8415 - val_loss: 2.5982 - val_accuracy: 0.5628\n",
      "Epoch 18/40\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 0.5671 - accuracy: 0.8284 - val_loss: 3.7548 - val_accuracy: 0.3754\n",
      "Epoch 19/40\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 0.5305 - accuracy: 0.8386 - val_loss: 5.7422 - val_accuracy: 0.4516\n",
      "Epoch 20/40\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 0.4903 - accuracy: 0.8417 - val_loss: 5.1293 - val_accuracy: 0.6698\n",
      "Epoch 21/40\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 0.4808 - accuracy: 0.8430 - val_loss: 12.7956 - val_accuracy: 0.3996\n",
      "Epoch 22/40\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 0.4625 - accuracy: 0.8479 - val_loss: 10.6578 - val_accuracy: 0.6700\n",
      "Epoch 23/40\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 0.4554 - accuracy: 0.8441 - val_loss: 9.5085 - val_accuracy: 0.6701\n",
      "Epoch 24/40\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 0.4539 - accuracy: 0.8470 - val_loss: 11.0273 - val_accuracy: 0.6700\n",
      "Epoch 25/40\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 0.4206 - accuracy: 0.8551 - val_loss: 12.9862 - val_accuracy: 0.6702\n",
      "Epoch 26/40\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 0.4363 - accuracy: 0.8437 - val_loss: 14.5289 - val_accuracy: 0.6700\n",
      "Epoch 27/40\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 0.4707 - accuracy: 0.8348 - val_loss: 21.5352 - val_accuracy: 0.6700\n",
      "Epoch 28/40\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 0.4590 - accuracy: 0.8410 - val_loss: 6.6641 - val_accuracy: 0.6646\n",
      "Epoch 29/40\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 0.4240 - accuracy: 0.8511 - val_loss: 15.2167 - val_accuracy: 0.6701\n",
      "Epoch 30/40\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 0.4402 - accuracy: 0.8427 - val_loss: 19.5698 - val_accuracy: 0.6701\n",
      "Epoch 31/40\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 0.4108 - accuracy: 0.8513 - val_loss: 19.1082 - val_accuracy: 0.6702\n",
      "Epoch 32/40\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 0.3914 - accuracy: 0.8554 - val_loss: 11.1911 - val_accuracy: 0.6700\n",
      "Epoch 33/40\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 0.4094 - accuracy: 0.8525 - val_loss: 10.3679 - val_accuracy: 0.6698\n",
      "Epoch 34/40\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 0.4359 - accuracy: 0.8411 - val_loss: 5.4035 - val_accuracy: 0.6698\n",
      "Epoch 35/40\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 0.4365 - accuracy: 0.8442 - val_loss: 11.7583 - val_accuracy: 0.6700\n",
      "Epoch 36/40\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 0.4080 - accuracy: 0.8523 - val_loss: 16.1775 - val_accuracy: 0.6701\n",
      "Epoch 37/40\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 0.4115 - accuracy: 0.8472 - val_loss: 9.4992 - val_accuracy: 0.6702\n",
      "Epoch 38/40\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 0.3905 - accuracy: 0.8558 - val_loss: 9.0572 - val_accuracy: 0.6699\n",
      "Epoch 39/40\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 0.4168 - accuracy: 0.8456 - val_loss: 5.4609 - val_accuracy: 0.6701\n",
      "Epoch 40/40\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 0.4394 - accuracy: 0.8411 - val_loss: 5.6321 - val_accuracy: 0.4561\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "# time taken to train the model\n",
    "\n",
    "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=40, shuffle=True, batch_size=100, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-12T11:26:21.834783Z",
     "start_time": "2023-04-12T11:26:21.621362Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182/182 [==============================] - 0s 911us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 1       0.76      0.72      0.74      1892\n",
      "     Class 2       0.87      0.89      0.88      3912\n",
      "\n",
      "    accuracy                           0.83      5804\n",
      "   macro avg       0.81      0.80      0.81      5804\n",
      "weighted avg       0.83      0.83      0.83      5804\n",
      "\n",
      "Test Accuracy 2: 83.3907649896623\n"
     ]
    }
   ],
   "source": [
    "\"\"\"# Model Evaluation\n",
    "\n",
    "## Mode Accuracy, f1-score and recall\n",
    "\"\"\"\n",
    "\n",
    "# #Evaluate model\n",
    "y_pred = model.predict(X_test)\n",
    "# #print (y_pred)\n",
    "y_pred = (y_pred > 0.5).astype(int)\n",
    "\n",
    "# #Define target names\n",
    "target_names = ['Class 1', 'Class 2']\n",
    "\n",
    "# # Generate classification report\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "accuracy = accuracy_score(y_pred, y_test) * 100\n",
    "\n",
    "print(\"Test Accuracy 2:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-12T11:26:21.875922Z",
     "start_time": "2023-04-12T11:26:21.838274Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'test_output.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m export_test \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(test_dataset_location)\n\u001b[1;32m      9\u001b[0m output_location \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_output.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 10\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_location\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Encode categorical features\u001b[39;00m\n\u001b[1;32m     13\u001b[0m label_encoder \u001b[38;5;241m=\u001b[39m LabelEncoder()\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1706\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1711\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1712\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1714\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    866\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    867\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'test_output.csv'"
     ]
    }
   ],
   "source": [
    "\"\"\"## Predictions for Test dataset\n",
    "\n",
    "### Import/Format the Test dataset\n",
    "\"\"\"\n",
    "test_dataset_location = 'test.csv'\n",
    "test = pd.read_csv(test_dataset_location)\n",
    "export_test = pd.read_csv(test_dataset_location)\n",
    "\n",
    "output_location = 'test_output.csv'\n",
    "output = pd.read_csv(output_location)\n",
    "\n",
    "# Encode categorical features\n",
    "label_encoder = LabelEncoder()\n",
    "test['BookingStatus'] = label_encoder.fit_transform(test['BookingStatus'])\n",
    "test['MarketSegment'] = label_encoder.fit_transform(test['MarketSegment'])\n",
    "test['MealPlan'] = label_encoder.fit_transform(test['MealPlan'])\n",
    "test['RoomType'] = label_encoder.fit_transform(test['RoomType'])\n",
    "\n",
    "# Add new feature 'leadTime'\n",
    "test['leadTime'] = test['LeadTime'] / 365.0\n",
    "\n",
    "# Normalize features\n",
    "mean = test.mean(axis=0)\n",
    "std = test.std(axis=0)\n",
    "test = (test - mean) / std\n",
    "test = (test - mean) / std\n",
    "\n",
    "print (test)\n",
    "\n",
    "test_x = test[['ArrivalMonth', 'AvgRoomPrice', 'MarketSegment', 'MealPlan', 'NumAdults', 'NumChildren', 'NumPrevCancellations', 'NumPreviousNonCancelled', 'NumWeekNights', 'NumWeekendNights', 'RepeatedGuest', 'RoomType', 'SpecialRequests', 'leadTime']]\n",
    "\n",
    "# Formating output file\n",
    "output['BookingStatus'] = label_encoder.fit_transform(output['BookingStatus'])\n",
    "\n",
    "output_y = output['BookingStatus']\n",
    "print(output_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-12T11:26:22.852964Z",
     "start_time": "2023-04-12T11:26:22.645787Z"
    }
   },
   "outputs": [],
   "source": [
    "# #Evaluate model\n",
    "y_pred = model.predict(test_x)\n",
    "y_pred = (y_pred > 0.5).astype(int)\n",
    "\n",
    "# #print (y_pred)\n",
    "\n",
    "# #Define target names\n",
    "target_names = ['Class 1', 'Class 2']\n",
    "\n",
    "# # Generate classification report\n",
    "print(classification_report(output_y, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-12T11:26:22.856492Z",
     "start_time": "2023-04-12T11:26:22.851919Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
